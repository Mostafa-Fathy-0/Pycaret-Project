{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150cc3e7",
   "metadata": {},
   "source": [
    "# Summary of project \n",
    "## this task is a simple shape of pycaret library it  seeks to provide a low-code machine learning ,it cosists of main aspects as follows ,it consists of two main classes and many essential functions.\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "## The first class is for Regression and contain some of important Regression algorithm methods , and these mathods are :\n",
    "\n",
    "### 1- simple_regression() :\n",
    "####  it performs simple regression model for one variable and graph it to show the fit line that shows target feature.\n",
    "\n",
    "### 2- polynomial_features() :\n",
    "#### it performs regression model for one variable and it using polynomial features to get the best fit line for target feature.\n",
    "\n",
    "### 3- Regularization() :\n",
    "#### it uses to algorithms to regularize features by using Lasso algorithm and also by using Ridge algorithm to improve model.\n",
    "\n",
    "### 4- gradient_descent() :\n",
    "#### it performs the gradient descent formula to minimize the cost function and optimize model parameters and graph target feature after applying this formula.\n",
    "\n",
    "### 5- multilinear_regression() :\n",
    "#### it performs simple regression model for multivariables features to get targets and graph the best fit line for it.\n",
    "\n",
    "### 6- model_evaluation() :\n",
    "#### it works to evaluate models by scaling training feature and apllay simple regression and polynomial features on dataset and perform a graph to show best fit line of target features.\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "## The second class is for Classification and contain some of important Classification algorithm methods , and these mathods are :\n",
    "\n",
    "### 1- logistic_regression() :\n",
    "#### it applies the logisitc regression and apply confusion matrix in dataset and perform graph  to visualize this algorithm.\n",
    "\n",
    "### 2- support_vector_machine() :\n",
    "#### it applies support vector machine algorithm on dataset and use diffirent kernals like linear , poly and rbf and perform visualization to this algorithm.\n",
    "\n",
    "### 3- K_nearest_neighbor() :\n",
    "#### it applies k nearst neighbor on dataset and use n_neighbors and polynomial feature to perform graph for this algorithm.\n",
    "\n",
    "### 4- decision_tree() :\n",
    "#### it applies descision tree algorithm on dataset and perform graph for this algorithm. \n",
    "\n",
    "### 5- random_forest() :\n",
    "#### it applies random forest on dataset and work to show some important information and perform a graph for it.\n",
    "\n",
    "### 6- boosting() :\n",
    "#### use xgboost and xgbclassifier to apply it on dataset and work to show some important information and perform a graph for it.\n",
    "\n",
    "### 7- cross_validation() :\n",
    "#### apply cross validation algorithm on dataset and show some important statistics to user.\n",
    "\n",
    "### 8- hyper_parameter_tuning() :\n",
    "#### apply hayper parameter tuning show some important informations to user.\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "## The essential functions are :\n",
    "\n",
    "### 1- get_files() :\n",
    "#### it's main role to get dataset file from user to allow him to apply differant machine learning algorithms on it.\n",
    "\n",
    "### 2- check_file_path() :\n",
    "#### it's main role to chek type of file that user has entered to perform that it's valid type or not valid and excepected to harmfull. \n",
    "\n",
    "### 3- data_preprocessing() :\n",
    "#### it's main role to make some of preprocessing steps on dataset including fill missing values if it is catogerical or numerical values and it also enclude step of Encoding to prepare dataset to be used in diffierent ML models.\n",
    "\n",
    "### 4- drop_column() :\n",
    "#### it's main role to allow user to drop any columns that not help him in it's work.\n",
    "\n",
    "### 5- choose_model_and_algorithms() :\n",
    "#### it's main role to allow user to choose which model he want to perform in dataset after processed and also it allow user to choose a specific algorithm perform.\n",
    "\n",
    "### 6- choose_features() :\n",
    "#### it's main role to allow user to assign values of columns to training data and target data to input them after that to different models to use them in apply diffirent algorithms\n",
    "\n",
    "### 7- main() :\n",
    "####  it's main role to run all of other method to explore and train diffirent machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc782e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error , r2_score , mean_absolute_error , accuracy_score , precision_score , recall_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975de27c",
   "metadata": {},
   "source": [
    "# Essiential Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003c253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_files(file_type):\n",
    "    while True :\n",
    "        file_path = input('Please enter your file path : ')\n",
    "        if file_path.endswith(tuple(file_type)):\n",
    "            return file_path\n",
    "        else :\n",
    "            print('Please enter a valid path from this range {}'.format(file_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f429f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_file_path(file_path):\n",
    "    \n",
    "    if file_path.endswith('csv'):\n",
    "        df = pd.read_csv(file_path.strip())\n",
    "        \n",
    "    elif file_path.endswith('xlsx'):\n",
    "        df = pd.read_excel(file_path.strip())\n",
    "        \n",
    "    elif file_path.endswith('sql'):\n",
    "        df = pd.read_sql(file_path.strip())\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a3859a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(df) :\n",
    "    # handle null values\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    print('Sum of all null values before handling : \\n')\n",
    "    print(df.isna().sum())\n",
    "    print('------------------------------------------')\n",
    "    mean_imputer = SimpleImputer(strategy='mean' , missing_values=np.nan)\n",
    "    mode_imputer = SimpleImputer(strategy='most_frequent' , missing_values=np.nan)\n",
    "    median_imputer = SimpleImputer(strategy='median', missing_values=np.nan)\n",
    "    missing_columns_values = df.columns[df.isnull().any()]\n",
    "    for column in missing_columns_values :\n",
    "        if df[column].dtype == 'object' or df[column].dtype == 'bool' :\n",
    "            df[column] = mode_imputer.fit_transform(df[column].values.reshape(-1,1))\n",
    "        elif df[column].isnull().any() :\n",
    "            if df[column].isnull().sum() >= 3500 :\n",
    "                print(f\"Droping column '{column}' due to a large number of missing values.\")\n",
    "            else :\n",
    "                df[column] = mean_imputer.fit_transform(df[column].values.reshape(-1, 1))\n",
    "        elif df[column].isnull().sum() == 0 :\n",
    "            print(f\"Droping column '{column}' as it has no missing values.\")\n",
    "            df.drop(columns=column, inplace=True)\n",
    "    print('Sum of all null values after handling : ')\n",
    "    print(df.isna().sum())\n",
    "    # encoding\n",
    "    le = LabelEncoder()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            if df[column].isin(['YES', 'NO', 'yes', 'no', 'Male', 'Female', 'male', 'female']).any():\n",
    "                df[column] = le.fit_transform(df[column])\n",
    "            else :\n",
    "                df = pd.get_dummies(df, columns=[column], drop_first=True)\n",
    "        elif df[column].dtype == 'bool':\n",
    "            df[column] = df[column].astype(int)\n",
    "        elif df[column].dtype in ['int64','float64'] :\n",
    "            pass\n",
    "        else :\n",
    "            df = pd.get_dummies(df, columns=[column], drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cce8af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    while True:\n",
    "        try:\n",
    "            print('Columns in DataFrame:')\n",
    "            print('[', ', '.join(df.columns), ']')\n",
    "            \n",
    "            columns_to_drop = input('Enter the names of columns to drop (comma-separated, press Enter to finish): ')\n",
    "            \n",
    "            if not columns_to_drop:\n",
    "                break\n",
    "            \n",
    "            columns_to_drop = [col.strip() for col in columns_to_drop.split(',')]\n",
    "            \n",
    "            invalid_columns = [col for col in columns_to_drop if col not in df.columns]\n",
    "            \n",
    "            if invalid_columns:\n",
    "                print('Columns not found in the DataFrame:', ', '.join(invalid_columns))\n",
    "            else:\n",
    "                df.drop(columns=columns_to_drop, inplace=True)\n",
    "                print('Columns \"{}\" have been dropped.'.format(', '.join(columns_to_drop)))\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d85a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def choose_features(df):\n",
    "    print('Columns In DataFrame:')\n",
    "    print(df.columns)\n",
    "    print('------------------------------')\n",
    "    \n",
    "    while True:\n",
    "        x_input = input('Please choose one or many columns to assign to x (comma-separated): ')\n",
    "        x_columns = [col.strip() for col in x_input.split(',')]\n",
    "        \n",
    "        if all(col in df.columns for col in x_columns):\n",
    "            break\n",
    "        else:\n",
    "            print('Invalid column names, please try again.')\n",
    "    \n",
    "    while True:\n",
    "        y_columns = input('Please choose a column to assign to y : ')\n",
    "        if y_columns not in df.columns :\n",
    "            print('Wrong answer , Please try again ')\n",
    "        else :\n",
    "            break\n",
    "        \n",
    "    return x_columns, y_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b9610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def choose_model_and_algorithm(x, y, df):\n",
    "    while True:\n",
    "        try:\n",
    "            model = input('Please enter your machine learning model type (regression/classification): ')\n",
    "            if model.lower() == 'regression':\n",
    "                print('These are the main algorithms in the regression class:')\n",
    "                print('1-simple_regression \\n2-polynomial_features\\n3-Regularization\\n4-gradient_descent\\n5-multilinear_regression\\n6-model_evaluation')\n",
    "                break\n",
    "            elif model.lower() == 'classification':\n",
    "                print('These are the main algorithms in the classification class:')\n",
    "                print('1-logistic_regression\\n2-support_vector_machine\\n3-K_nearest_neighbor\\n4-decision_tree\\n5-random_forest\\n6-boosting\\n7-cross_validation\\n8-hyper_parameter_tuning')\n",
    "                break\n",
    "            else:\n",
    "                print('Wrong type, please enter a valid model type.')\n",
    "        except Exception as e:\n",
    "            print(f'Error: {str(e)}')\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            algorithm = int(input(f'Please enter the number of the {model} algorithm you want to apply: '))\n",
    "            if model.lower() == 'regression':\n",
    "                rg = Regression(x, y,df)\n",
    "                if algorithm == 1:\n",
    "                    rg.simple_regression()\n",
    "                elif algorithm == 2:\n",
    "                    rg.polynomial_features()\n",
    "                elif algorithm == 3:\n",
    "                    rg.Regularization()\n",
    "                elif algorithm == 4:\n",
    "                    rg.gradient_descent()\n",
    "                elif algorithm == 5:\n",
    "                    rg.multilinear_regression()\n",
    "                elif algorithm == 6:\n",
    "                    rg.model_evaluation()\n",
    "                else:\n",
    "                    print('Wrong number, please try again')\n",
    "                    continue\n",
    "                return  \n",
    "            elif model.lower() == 'classification':\n",
    "                cls = Classification(df, y)\n",
    "                if algorithm == 1:\n",
    "                    cls.logistic_regression()\n",
    "                elif algorithm == 2:\n",
    "                    cls.support_vector_machine()\n",
    "                elif algorithm == 3:\n",
    "                    cls.k_nearest_neighbor()\n",
    "                elif algorithm == 4:\n",
    "                    cls.decision_tree()\n",
    "                elif algorithm == 5:\n",
    "                    cls.random_forest()\n",
    "                elif algorithm == 6:\n",
    "                    cls.boosting()\n",
    "                elif algorithm == 7:\n",
    "                    cls.cross_validation()\n",
    "                elif algorithm == 8:\n",
    "                    cls.hyper_parameter_tuning()\n",
    "                else:\n",
    "                    print('Wrong number, please try again')\n",
    "                    continue\n",
    "                return  \n",
    "            else:\n",
    "                print('Invalid model type, please try again.')\n",
    "        except ValueError:\n",
    "            print('Invalid input. Please enter a valid number.')\n",
    "        except Exception as e:\n",
    "            print(f'Error: {str(e)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e17f7a",
   "metadata": {},
   "source": [
    "# Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e2f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Regression:\n",
    "    def __init__(self, x, y, df):\n",
    "        self.df = df\n",
    "        self.x = [col if isinstance(col, str) else str(col) for col in x]\n",
    "        self.y = self.df[y]\n",
    "\n",
    "    def simple_regression(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Simple Regression Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        for col in self.x:\n",
    "            x_data = self.df[col].values.reshape(-1, 1)\n",
    "            lr = LinearRegression()\n",
    "            lr.fit(x_data, self.y)\n",
    "            print(f\"Results for column '{col}':\")\n",
    "            print('---------------------------')\n",
    "            print(\"Coefficients =\", lr.coef_)\n",
    "            print(\"Intercept =\", lr.intercept_)\n",
    "            prdic = lr.predict(x_data)\n",
    "            plt.scatter(x_data, self.y)\n",
    "            plt.plot(x_data, prdic, color='r')\n",
    "            mse = mean_squared_error(self.y, prdic)\n",
    "            r2 = r2_score(self.y, prdic)\n",
    "            mae = mean_absolute_error(self.y, prdic)\n",
    "            print(\"Mean Squared Error =\", mse)\n",
    "            print(\"R^2 Score =\", r2)\n",
    "            print(\"Mean Absolute Error =\", mae)\n",
    "            print('---------------------------')\n",
    "            print('---------------------------')\n",
    "\n",
    "    def polynomial_features(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Polynomial Features Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        for col in self.x:\n",
    "            x_data = self.df[col].values.reshape(-1, 1)\n",
    "            poly = PolynomialFeatures(degree=3)\n",
    "            x_poly = poly.fit_transform(x_data)\n",
    "            scl = StandardScaler()\n",
    "            x_scl = scl.fit_transform(x_poly)\n",
    "            lr = LinearRegression()\n",
    "            lr.fit(x_scl, self.y)\n",
    "            prdic = lr.predict(x_scl)\n",
    "            print(f\"Results for column '{col}':\")\n",
    "            print('---------------------------')\n",
    "            print(\"Coefficients =\", lr.coef_)\n",
    "            print(\"Intercept =\", lr.intercept_)\n",
    "            print('R^2 Score before poly --->', r2_score(self.y, prdic))\n",
    "            lr_poly = LinearRegression()\n",
    "            lr_poly.fit(x_scl, self.y)\n",
    "            preds_poly = lr_poly.predict(x_scl)\n",
    "            print('R^2 Score after poly --->', r2_score(self.y, preds_poly))\n",
    "            plt.scatter(x_data, self.y)\n",
    "            plt.plot(x_data, prdic, color='g')\n",
    "            plt.plot(x_data, preds_poly, color='r')\n",
    "            plt.show()\n",
    "            mse = mean_squared_error(self.y, prdic)\n",
    "            r2 = r2_score(self.y, prdic)\n",
    "            mae = mean_absolute_error(self.y, prdic)\n",
    "            print(\"Mean Squared Error =\", mse)\n",
    "            print(\"R^2 Score =\", r2)\n",
    "            print(\"Mean Absolute Error =\", mae)\n",
    "            print('---------------------------')\n",
    "            print('---------------------------')\n",
    "\n",
    "    def Regularization(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Regularization Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        print('-----------------------------')\n",
    "        print('Regularization By Lasso ')\n",
    "        print('-----------------------------')\n",
    "        for alpha in [0.00001, 0.0001, 0.001, 0.01, 0.1, 0, 1, 10, 100, 1000]:\n",
    "            for col in self.x:\n",
    "                x_data = self.df[col].values.reshape(-1, 1)\n",
    "                poly = PolynomialFeatures(degree=15)\n",
    "                x_poly = poly.fit_transform(x_data)\n",
    "                scl = StandardScaler()\n",
    "                x_scl = scl.fit_transform(x_poly)\n",
    "                lr_poly = Lasso(alpha=alpha)\n",
    "                lr_poly.fit(x_scl, self.y)\n",
    "                preds_poly = lr_poly.predict(x_scl)\n",
    "                print(f\"Results for column '{col}' with alpha =\", alpha)\n",
    "                print('---------------------------')\n",
    "                print('R^2 Score after poly --->', r2_score(self.y, preds_poly))\n",
    "                plt.scatter(x_data, self.y)\n",
    "                plt.plot(x_data, preds_poly, color='r')\n",
    "                plt.show()\n",
    "                print('---------------------------')\n",
    "                print('---------------------------')\n",
    "\n",
    "        print('-----------------------------')\n",
    "        print('Regularization By Ridge ')\n",
    "        print('-----------------------------')\n",
    "        for alpha in [0.00001, 0.0001, 0.001, 0.01, 0.1, 0, 1, 10, 100, 1000]:\n",
    "            for col in self.x:\n",
    "                x_data = self.df[col].values.reshape(-1, 1)\n",
    "                poly = PolynomialFeatures(degree=15)\n",
    "                x_poly = poly.fit_transform(x_data)\n",
    "                scl = StandardScaler()\n",
    "                x_scl = scl.fit_transform(x_poly)\n",
    "                lr_poly = Ridge(alpha=alpha)\n",
    "                lr_poly.fit(x_scl, self.y)\n",
    "                preds_poly = lr_poly.predict(x_scl)\n",
    "                print(f\"Results for column '{col}' with alpha =\", alpha)\n",
    "                print('---------------------------')\n",
    "                print('R^2 Score after poly --->', r2_score(self.y, preds_poly))\n",
    "                plt.scatter(x_data, self.y)\n",
    "                plt.plot(x_data, preds_poly, color='r')\n",
    "                plt.show()\n",
    "                print('---------------------------')\n",
    "                print('---------------------------')\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Gradient Descent Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        for col in self.x:\n",
    "            x_data = self.df[col].values.reshape(-1, 1)\n",
    "            sgdr = SGDRegressor()\n",
    "            poly = PolynomialFeatures(degree=15)\n",
    "            x_poly = poly.fit_transform(x_data)\n",
    "            scl = StandardScaler()\n",
    "            x_scl = scl.fit_transform(x_poly)\n",
    "            x_scaled_1 = scl.fit_transform(x_data)\n",
    "            sgdr.fit(x_scaled_1, self.y)\n",
    "            preds_sgdr = sgdr.predict(x_scaled_1)\n",
    "            plt.scatter(x_data, self.y)\n",
    "            plt.plot(x_data, preds_sgdr, color='r')\n",
    "            plt.show()\n",
    "            mse = mean_squared_error(self.y, preds_sgdr)\n",
    "            r2 = r2_score(self.y, preds_sgdr)\n",
    "            mae = mean_absolute_error(self.y, preds_sgdr)\n",
    "            print(\"Results for column '{}'\".format(col))\n",
    "            print('---------------------------')\n",
    "            print(\"Mean Squared Error =\", mse)\n",
    "            print(\"R^2 Score =\", r2)\n",
    "            print(\"Mean Absolute Error =\", mae)\n",
    "            poly = PolynomialFeatures(degree=15)\n",
    "            x_poly = poly.fit_transform(x_data)\n",
    "            scl = StandardScaler()\n",
    "            x_scl = scl.fit_transform(x_poly)\n",
    "            lr_poly = SGDRegressor()\n",
    "            lr_poly.fit(x_scl, self.y)\n",
    "            preds_poly = lr_poly.predict(x_scl)\n",
    "            plt.scatter(x_data, self.y)\n",
    "            plt.plot(x_data, preds_poly, color='r')\n",
    "            plt.show()\n",
    "            mse = mean_squared_error(self.y, preds_poly)\n",
    "            r2 = r2_score(self.y, preds_poly)\n",
    "            mae = mean_absolute_error(self.y, preds_poly)\n",
    "            print(\"Results for column '{}'\".format(col))\n",
    "            print(\"Mean Squared Error =\", mse)\n",
    "            print(\"R^2 Score =\", r2)\n",
    "            print(\"Mean Absolute Error =\", mae)\n",
    "            print('---------------------------')\n",
    "            print('---------------------------')\n",
    "\n",
    "    def multilinear_regression(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Multilinear Regression Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        msc = MinMaxScaler()\n",
    "        for col in self.x:\n",
    "            x_data = self.df[col].values.reshape(-1, 1)\n",
    "            x_scl = msc.fit_transform(x_data)\n",
    "            print(f'Results for column \"{col}\" after scaling:')\n",
    "            print('---------------------------')\n",
    "            print(' x after scaling = ', x_scl[0:5])\n",
    "            lr = LinearRegression()\n",
    "            lr.fit(x_scl, self.y)\n",
    "            preds = lr.predict(x_scl)\n",
    "            print('R^2 Score =', r2_score(self.y, preds))\n",
    "            plt.scatter(x_data, self.y)\n",
    "            plt.plot(x_data, preds, color='g')\n",
    "            plt.show()\n",
    "            poly = PolynomialFeatures(degree=4)\n",
    "            x_poly = poly.fit_transform(x_scl)\n",
    "            x_scaled_poly = msc.fit_transform(x_poly)\n",
    "            lr.fit(x_scaled_poly, self.y)\n",
    "            preds_poly = lr.predict(x_scaled_poly)\n",
    "            print('Results for column \"{}\" after polynomial features:'.format(col))\n",
    "            print('R^2 Score =', r2_score(self.y, preds_poly))\n",
    "            plt.scatter(x_data, self.y)\n",
    "            plt.plot(x_data, preds_poly, color='r')\n",
    "            plt.show()\n",
    "            print('---------------------------')\n",
    "            print('---------------------------')\n",
    "\n",
    "    def model_evaluation(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Model Evaluation Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        msc = MinMaxScaler()\n",
    "        for col in self.x:\n",
    "            x_data = self.df[col].values.reshape(-1, 1)\n",
    "            x_scl = msc.fit_transform(x_data)\n",
    "            print(f'Results for column \"{col}\" after scaling:')\n",
    "            print(' x after scaling = ', x_scl[0:10])\n",
    "            print('---------------------------')\n",
    "            lr = LinearRegression()\n",
    "            lr.fit(x_scl, self.y)\n",
    "            preds = lr.predict(x_scl)\n",
    "            print('R^2 Score =', r2_score(self.y, preds))\n",
    "            poly = PolynomialFeatures(degree=4)\n",
    "            x_poly = poly.fit_transform(x_scl)\n",
    "            x_scaled_poly = msc.fit_transform(x_poly)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x_scaled_poly, self.y, test_size=0.2)\n",
    "            lr.fit(x_train, y_train)\n",
    "            train_preds = lr.predict(x_train)\n",
    "            test_preds = lr.predict(x_test)\n",
    "            print(f'Results for column \"{col}\" after polynomial features:')\n",
    "            print('Before polynomial features:')\n",
    "            print('R^2 Score (train) =', r2_score(y_train, train_preds))\n",
    "            print('R^2 Score (test) =', r2_score(y_test, test_preds))\n",
    "            lr.fit(x_train, y_train)\n",
    "            train_preds = lr.predict(x_train)\n",
    "            test_preds = lr.predict(x_test)\n",
    "            print('After polynomial features:')\n",
    "            print('R^2 Score (train) =', r2_score(y_train, train_preds))\n",
    "            print('R^2 Score (test) =', r2_score(y_test, test_preds))\n",
    "            print('---------------------------')\n",
    "            print('---------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a0b155",
   "metadata": {},
   "source": [
    "# Classification Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12630a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Classification:\n",
    "    def __init__(self, df, target):\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "        self.x = self.df.drop(self.target, axis=1)\n",
    "        self.x = StandardScaler().fit_transform(self.x)\n",
    "        self.y = self.df[self.target]\n",
    "\n",
    "    def logistic_regression(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Logistic Regression Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.x, self.y, test_size=0.2, shuffle=True)\n",
    "        \n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train, y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, train_pred))\n",
    "        disp.plot(cmap='viridis')\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for train', accuracy_score(y_train, train_pred))\n",
    "        print('Precision Score for train', precision_score(y_train, train_pred))\n",
    "        print('Recall Score for train', recall_score(y_train, train_pred))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title('Confusion matrix for test')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for test', accuracy_score(y_test, test_pred))\n",
    "        print('Precision Score for test', precision_score(y_test, test_pred))\n",
    "        print('Recall Score for test', recall_score(y_test, test_pred))\n",
    "\n",
    "    def support_vector_machine(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Support Vector Machine Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.x, self.y, test_size=0.2, shuffle=True)\n",
    "        \n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train, y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, train_pred))\n",
    "        disp.plot(cmap='viridis')\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for train', accuracy_score(y_train, train_pred))\n",
    "        print('Precision Score for train', precision_score(y_train, train_pred))\n",
    "        print('Recall Score for train', recall_score(y_train, train_pred))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title('Confusion matrix for test')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for test', accuracy_score(y_test, test_pred))\n",
    "        print('Precision Score for test', precision_score(y_test, test_pred))\n",
    "        print('Recall Score for test', recall_score(y_test, test_pred))\n",
    "    \n",
    "    def k_nearest_neighbor(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('K Nearest Neighbor Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "       \n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.x, self.y, test_size=0.2, shuffle=True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train, y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, train_pred))\n",
    "        disp.plot(cmap='viridis')\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for train', accuracy_score(y_train, train_pred))\n",
    "        print('Precision Score for train', precision_score(y_train, train_pred))\n",
    "        print('Recall Score for train', recall_score(y_train, train_pred))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title('Confusion matrix for test')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for test', accuracy_score(y_test, test_pred))\n",
    "        print('Precision Score for test', precision_score(y_test, test_pred))\n",
    "        print('Recall Score for test', recall_score(y_test, test_pred))\n",
    "        \n",
    "\n",
    "    def decision_tree(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Decision Tree Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.x, self.y, test_size=0.2, shuffle=True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train, y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, train_pred))\n",
    "        disp.plot(cmap='viridis')\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for train', accuracy_score(y_train, train_pred))\n",
    "        print('Precision Score for train', precision_score(y_train, train_pred))\n",
    "        print('Recall Score for train', recall_score(y_train, train_pred))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title('Confusion matrix for test')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for test', accuracy_score(y_test, test_pred))\n",
    "        print('Precision Score for test', precision_score(y_test, test_pred))\n",
    "        print('Recall Score for test', recall_score(y_test, test_pred))\n",
    "        \n",
    "        \n",
    "    def random_forest(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Random Forest Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.x, self.y, test_size=0.2, shuffle=True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train, y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, train_pred))\n",
    "        disp.plot(cmap='viridis')\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for train', accuracy_score(y_train, train_pred))\n",
    "        print('Precision Score for train', precision_score(y_train, train_pred))\n",
    "        print('Recall Score for train', recall_score(y_train, train_pred))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title('Confusion matrix for test')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for test', accuracy_score(y_test, test_pred))\n",
    "        print('Precision Score for test', precision_score(y_test, test_pred))\n",
    "        print('Recall Score for test', recall_score(y_test, test_pred))\n",
    "        \n",
    "    def boosting(self):\n",
    "        print('-----------------------------------------')\n",
    "        print('Boosting Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.x, self.y, test_size=0.2, shuffle=True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train, y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, train_pred))\n",
    "        disp.plot(cmap='viridis')\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for train', accuracy_score(y_train, train_pred))\n",
    "        print('Precision Score for train', precision_score(y_train, train_pred))\n",
    "        print('Recall Score for train', recall_score(y_train, train_pred))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title('Confusion matrix for test')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for test', accuracy_score(y_test, test_pred))\n",
    "        print('Precision Score for test', precision_score(y_test, test_pred))\n",
    "        print('Recall Score for test', recall_score(y_test, test_pred))\n",
    "    def cross_validation(self): \n",
    "        print('-----------------------------------------')\n",
    "        print('Cross Validation Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_preds = clf.predict(x_train)\n",
    "        test_preds = clf.predict(x_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, train_preds))\n",
    "        disp.plot(cmap='viridis')\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "        print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_preds))\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        clf = RandomForestClassifier()\n",
    "        kf = StratifiedKFold(n_splits = 5)\n",
    "        acc_list = []\n",
    "        for train_idx , test_idx in kf.split(self.x,self.y) :\n",
    "            train_data = self.x[train_idx]\n",
    "            test_data = self.x[test_idx]\n",
    "            train_y = self.y.iloc[train_idx]\n",
    "            test_y = self.y.iloc[test_idx]\n",
    "            clf.fit(train_data,train_y)\n",
    "            preds = clf.predict(test_data)\n",
    "            acc = accuracy_score(test_y, preds)\n",
    "            acc_list.append(acc)\n",
    "        print('List of accuracies = ', acc_list)\n",
    "    def hyper_parameter_tuning(self) :\n",
    "        print('-----------------------------------------')\n",
    "        print('Hyper Parameter Tuning Algorithm')\n",
    "        print('-----------------------------------------')\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, train_pred))\n",
    "        disp.plot(cmap='viridis')\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        parameters = {'n_estimators' : [10,20,50,70,100],'max_depth' : [1,2,3,4,5]}\n",
    "        clf = RandomForestClassifier()\n",
    "        gsclf = GridSearchCV(clf,parameters)\n",
    "        gsclf.fit(x_train,y_train)\n",
    "        dgs = pd.DataFrame(gsclf.cv_results_)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title('Confusion matrix for test')\n",
    "        plt.show()\n",
    "        print(dgs[0:5])\n",
    "        model = gsclf.best_estimator_\n",
    "        model.fit(x_train,y_train)\n",
    "        preds = model.predict(x_test)\n",
    "        print('------------------------------------------------')\n",
    "        print('Accuracy Score = ',accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b44d3",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26b61c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('Welcome to the simplified version of pycaret.\nLet's get started!')\n",
    "    file_type = ['.csv','.xlsx','.sql']\n",
    "    file_path = get_files(file_type)\n",
    "    df = check_file_path(file_path)\n",
    "    drop_columns(df)\n",
    "    df=data_preprocessing(df)\n",
    "    x,y = choose_features(df)\n",
    "    choose_model_and_algorithm(x,y,df) \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc35a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94e9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af828e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fb000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33f328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecba72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd7495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3e3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2263958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb945a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe6258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
