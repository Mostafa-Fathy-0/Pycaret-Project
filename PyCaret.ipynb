{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150cc3e7",
   "metadata": {},
   "source": [
    "# Summary of project \n",
    "## this task is a simple shape of pycaret library it  seek to provide a low-code machine learning and this project cosists of main aspects as followed ,it consists of two main classes and many of essential  functions.\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "## The first class is for Regression and contain some of important Regression algorithm methods , and these mathods are :\n",
    "\n",
    "### 1- simple_regression() :\n",
    "####  it performs simple regression model for one variable and graph it to show the fit line that shows target feature.\n",
    "\n",
    "### 2- polynomial_features() :\n",
    "#### it performs regression model for one variable and it using polynomial features to get the best fit line for target feature.\n",
    "\n",
    "### 3- Regularization() :\n",
    "#### it uses to algorithms to regularize features by using Lasso algorithm and also by using Ridge algorithm to improve model.\n",
    "\n",
    "### 4- gradient_descent() :\n",
    "#### it performs the gradient descent formula to minimize the cost function and optimize model parameters and graph target feature after applying this formula.\n",
    "\n",
    "### 5- multilinear_regression() :\n",
    "#### it performs simple regression model for multivariables features to get targets and graph the best fit line for it.\n",
    "\n",
    "### 6- model_evaluation() :\n",
    "#### it works to evaluate models by scaling training feature and apllay simple regression and polynomial features on dataset and perform a graph to show best fit line of target features.\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "## The second class is for Classification and contain some of important Classification algorithm methods , and these mathods are :\n",
    "\n",
    "### 1- logistic_regression() :\n",
    "#### it applies the logisitc regression and apply confusion matrix in dataset and perform graph  to visualize this algorithm.\n",
    "\n",
    "### 2- support_vector_machine() :\n",
    "#### it applies support vector machine algorithm on dataset and use diffirent kernals like linear , poly and rbf and perform visualization to this algorithm.\n",
    "\n",
    "### 3- K_nearest_neighbor() :\n",
    "#### it applies k nearst neighbor on dataset and use n_neighbors and polynomial feature to perform graph for this algorithm.\n",
    "\n",
    "### 4- decision_tree() :\n",
    "#### it applies descision tree algorithm on dataset and perform graph for this algorithm. \n",
    "\n",
    "### 5- random_forest() :\n",
    "#### it applies random forest on dataset and asks user to enter location of training feature and target feature to perform a graph for it.\n",
    "\n",
    "### 6- boosting() :\n",
    "#### use xgboost and xgbclassifier to apply it on dataset and asks user to enter location of training feature and target feature to perform a graph for it.\n",
    "\n",
    "### 7- cross_validation() :\n",
    "#### apply cross validation algorithm on dataset and show some important statistics to user.\n",
    "\n",
    "### 8- hyper_parameter_tuning() :\n",
    "#### apply hayper parameter tuning show some important informations to user.\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "## The essential functions are :\n",
    "\n",
    "### 1- get_files() :\n",
    "#### it's main role to get dataset file from user to allow him to apply differant machine learning algorithms on it.\n",
    "\n",
    "### 2- check_file_path() :\n",
    "#### it's main role to chek type of file that user has entered to perform that it's valid type or not valid and excepected to harmfull. \n",
    "\n",
    "### 3- data_preprocessing() :\n",
    "#### it's main role to make some of preprocessing steps on dataset including fill missing values if it is catogerical or numerical values and it also enclude step of Encoding to prepare dataset to be used in diffierent ML models.\n",
    "\n",
    "### 4- drop_column() :\n",
    "#### it's main role to allow user to drop any columns that not help him in it's work.\n",
    "\n",
    "### 5- choose_model_and_algorithms() :\n",
    "#### it's main role to allow user to choose which model he want to perform in dataset after processed and also it allow user to choose a specific algorithm perform.\n",
    "\n",
    "### 6- choose_features() :\n",
    "#### it's main role to allow user to assign values of columns to training data and target data to input them after that to model to work\n",
    "\n",
    "### 7- choose_target_column() :\n",
    "#### it's main role to take a specific column and input it to classification class to use it to generate training data features ''X\" and target data features \"y\" to be used in diffirent classification algorithms. \n",
    "\n",
    "### 8- main() :\n",
    "####  it's main role to run all of other method to explore and train diffirent machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "from sklearn.metrics import mean_squared_error , r2_score , mean_absolute_error , accuracy_score , precision_score , recall_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975de27c",
   "metadata": {},
   "source": [
    "# Essiential Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(file_type):\n",
    "    while True :\n",
    "        file_path = input('Please enter your file path : ')\n",
    "        if file_path.endswith(tuple(file_type)):\n",
    "            return file_path\n",
    "        else :\n",
    "            print('Please enter a valid path from this range {}'.format(file_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_path(file_path):\n",
    "    \n",
    "    if file_path.endswith('csv'):\n",
    "        df = pd.read_csv(file_path.strip())\n",
    "        \n",
    "    elif file_path.endswith('xlsx'):\n",
    "        df = pd.read_excel(file_path.strip())\n",
    "        \n",
    "    elif file_path.endswith('sql'):\n",
    "        df = pd.read_sql(file_path.strip())\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a3859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df) :\n",
    "    # handle null values\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    print('Sum of all null values before handling : \\n')\n",
    "    print(df.isna().sum())\n",
    "    print('------------------------------------------')\n",
    "    mean_imputer = SimpleImputer(strategy='mean' , missing_values=np.nan)\n",
    "    mode_imputer = SimpleImputer(strategy='most_frequent' , missing_values=np.nan)\n",
    "    median_imputer = SimpleImputer(strategy='median', missing_values=np.nan)\n",
    "    missing_columns_values = df.columns[df.isnull().any()]\n",
    "    for column in missing_columns_values :\n",
    "        if df[column].dtype == 'object' or df[column].dtype == 'bool' :\n",
    "            df[column] = mode_imputer.fit_transform(df[column].values.reshape(-1,1))\n",
    "        elif df[column].isnull().any() :\n",
    "            if df[column].isnull().sum() >= 3500 :\n",
    "                print(f\"Droping column '{column}' due to a large number of missing values.\")\n",
    "            else :\n",
    "                df[column] = mean_imputer.fit_transform(df[column].values.reshape(-1, 1))\n",
    "        elif df[column].isnull().sum() == 0 :\n",
    "            print(f\"Droping column '{column}' as it has no missing values.\")\n",
    "            df.drop(columns=column, inplace=True)\n",
    "    print('Sum of all null values after handling : ')\n",
    "    print(df.isna().sum())\n",
    "    # encoding\n",
    "    le = LabelEncoder()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            if df[column].isin(['YES', 'NO', 'yes', 'no', 'Male', 'Female', 'male', 'female']).any():\n",
    "                df[column] = le.fit_transform(df[column])\n",
    "            else :\n",
    "                df = pd.get_dummies(df, columns=[column], drop_first=True)\n",
    "        elif df[column].dtype == 'bool':\n",
    "            df[column] = df[column].astype(int)\n",
    "        elif df[column].dtype in ['int64','float64'] :\n",
    "            pass\n",
    "        else :\n",
    "            df = pd.get_dummies(df, columns=[column], drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cce8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    while True:\n",
    "        try:\n",
    "            print('Columns in DataFrame:')\n",
    "            print('[', ', '.join(df.columns), ']')\n",
    "            \n",
    "            columns_to_drop = input('Enter the names of columns to drop (comma-separated, press Enter to finish): ')\n",
    "            \n",
    "            if not columns_to_drop:\n",
    "                break\n",
    "            \n",
    "            columns_to_drop = [col.strip() for col in columns_to_drop.split(',')]\n",
    "            \n",
    "            invalid_columns = [col for col in columns_to_drop if col not in df.columns]\n",
    "            \n",
    "            if invalid_columns:\n",
    "                print('Columns not found in the DataFrame:', ', '.join(invalid_columns))\n",
    "            else:\n",
    "                df.drop(columns=columns_to_drop, inplace=True)\n",
    "                print('Columns \"{}\" have been dropped.'.format(', '.join(columns_to_drop)))\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_features(df):\n",
    "    print('Columns In DataFrame : ')\n",
    "    print(df.columns)\n",
    "    while True :\n",
    "        x = input('Please choose a column to assign to x : ')\n",
    "        if x not in df.columns :\n",
    "            print('Wrong answer , Please try again ')\n",
    "        else :    \n",
    "            break\n",
    "    while True :\n",
    "        y = input('Please choose a column to assign to y : ')\n",
    "        if y not in df.columns :\n",
    "            print('Wrong answer , Please try again ')\n",
    "        else :\n",
    "            break\n",
    "    x = df[x]\n",
    "    y = df[y]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_model_and_algorithm(x, y, df, target):\n",
    "    while True:\n",
    "        try:\n",
    "            model = input('Please enter your machine learning model type (regression/classification): ')\n",
    "            if model.lower() == 'regression':\n",
    "                print('These are the main algorithms in the regression class:')\n",
    "                print('1-simple_regression \\n2-polynomial_features\\n3-Regularization\\n4-gradient_descent\\n5-multilinear_regression\\n6-model_evaluation')\n",
    "                break\n",
    "            elif model.lower() == 'classification':\n",
    "                print('These are the main algorithms in the classification class:')\n",
    "                print('1-logistic_regression\\n2-support_vector_machine\\n3-K_nearest_neighbor\\n4-decision_tree\\n5-random_forest\\n6-boosting\\n7-cross_validation\\n8-hyper_parameter_tuning')\n",
    "                break\n",
    "            else:\n",
    "                print('Wrong type, please enter a valid model type.')\n",
    "        except Exception as e:\n",
    "            print(f'Error: {str(e)}')\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            algorithm = int(input(f'Please enter the number of the {model} algorithm you want to apply: '))\n",
    "            if model.lower() == 'regression':\n",
    "                rg = Regression(x, y)\n",
    "                if algorithm == 1:\n",
    "                    rg.simple_regression()\n",
    "                elif algorithm == 2:\n",
    "                    rg.polynomial_features()\n",
    "                elif algorithm == 3:\n",
    "                    rg.Regularization()\n",
    "                elif algorithm == 4:\n",
    "                    rg.gradient_descent()\n",
    "                elif algorithm == 5:\n",
    "                    rg.multilinear_regression()\n",
    "                elif algorithm == 6:\n",
    "                    rg.model_evaluation()\n",
    "                else:\n",
    "                    print('Wrong number, please try again')\n",
    "                    continue\n",
    "                break\n",
    "            elif model.lower() == 'classification':\n",
    "                cls = Classification(df, target)\n",
    "                if algorithm == 1:\n",
    "                    cls.logistic_regression()\n",
    "                elif algorithm == 2:\n",
    "                    cls.support_vector_machine()\n",
    "                elif algorithm == 3:\n",
    "                    cls.K_nearest_neighbor()\n",
    "                elif algorithm == 4:\n",
    "                    cls.decision_tree()\n",
    "                elif algorithm == 5:\n",
    "                    cls.random_forest()\n",
    "                elif algorithm == 6:\n",
    "                    cls.boosting()\n",
    "                elif algorithm == 7:\n",
    "                    cls.cross_validation()\n",
    "                elif algorithm == 8:\n",
    "                    cls.hyper_parameter_tuning()\n",
    "                else:\n",
    "                    print('Wrong number, please try again')\n",
    "                    continue\n",
    "                break\n",
    "            else:\n",
    "                print('Invalid model type, please try again.')\n",
    "        except ValueError:\n",
    "            print('Invalid input. Please enter a valid number.')\n",
    "        except Exception as e:\n",
    "            print(f'Error: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_target_column(df):\n",
    "    print('Columns In DataFrame : ')\n",
    "    print(df.columns)\n",
    "    while True :\n",
    "        target = input('Please choose your target column for classification: ')\n",
    "        if target not in df.columns :\n",
    "            print('Wrong answer , Please try again')\n",
    "        else :    \n",
    "            break\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e17f7a",
   "metadata": {},
   "source": [
    "# Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression :\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def simple_regression(self) :\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(self.x.values.reshape(-1,1) , self.y.values.reshape(-1,1))\n",
    "        print(\"Coefficients = \", lr.coef_)\n",
    "        print(\"Intercept = \", lr.intercept_)\n",
    "        prdic = lr.predict(self.x.values.reshape(-1,1))\n",
    "        plt.scatter(self.x , self.y )\n",
    "        plt.plot(self.x , prdic , color = 'r' )\n",
    "        mse = mean_squared_error(self.y, prdic)\n",
    "        r2 = r2_score(self.y, prdic)\n",
    "        mae = mean_absolute_error(self.y, prdic)\n",
    "        print(\"Mean Squared Error = \", mse)\n",
    "        print(\"R^2 Score = \", r2)\n",
    "        print(\"Mean Absolute Error = \", mae)\n",
    "    def polynomial_features(self) :\n",
    "        poly = PolynomialFeatures(degree=3)\n",
    "        x_poly = poly.fit_transform(self.x.values.reshape(-1,1) )\n",
    "        scl = StandardScaler()\n",
    "        x_scl = scl.fit_transform(x_poly)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(self.x.values.reshape(-1,1) , self.y.values.reshape(-1,1))\n",
    "        prdic = lr.predict(self.x.values.reshape(-1,1))\n",
    "        print(\"Coefficients = \", lr.coef_)\n",
    "        print(\"Intercept = \", lr.intercept_)\n",
    "        lr_poly = LinearRegression()\n",
    "        lr_poly.fit(x_scl,self.y)\n",
    "        preds_poly = lr_poly.predict(x_scl)\n",
    "        print('R^2 Score before poly ---> ' , r2_score(self.y , prdic))\n",
    "        print('R^2 Score after poly ---> ' , r2_score(self.y , preds_poly))\n",
    "        plt.scatter(self.x,self.y)\n",
    "        plt.plot(self.x,prdic,color = 'g')\n",
    "        plt.plot(self.x,preds_poly,color='r')\n",
    "        plt.show()\n",
    "        mse = mean_squared_error(self.y, prdic)\n",
    "        r2 = r2_score(self.y, prdic)\n",
    "        mae = mean_absolute_error(self.y, prdic)\n",
    "        print(\"Mean Squared Error = \", mse)\n",
    "        print(\"R^2 Score = \", r2)\n",
    "        print(\"Mean Absolute Error = \", mae)\n",
    "        for i in range(1,20):\n",
    "            poly = PolynomialFeatures(degree=i)\n",
    "            x_poly = poly.fit_transform(self.x.values.reshape(-1,1))\n",
    "            scl = StandardScaler()\n",
    "            x_scl = scl.fit_transform(x_poly)\n",
    "            lr_poly = LinearRegression()\n",
    "            lr_poly.fit(x_scl,self.y)\n",
    "            preds_poly = lr_poly.predict(x_scl)\n",
    "            print('round number {}'.format(i))\n",
    "            plt.scatter(self.x,self.y)\n",
    "            plt.plot(self.x,preds_poly,color='r')\n",
    "            plt.show()\n",
    "            mse = mean_squared_error(self.y, prdic)\n",
    "            r2 = r2_score(self.y, prdic)\n",
    "            mae = mean_absolute_error(self.y, prdic)\n",
    "            print(\"Mean Squared Error = \", mse)\n",
    "            print(\"R^2 Score = \", r2)\n",
    "            print(\"Mean Absolute Error = \", mae)\n",
    "    def Regularization(self) :\n",
    "        print('-----------------------------')\n",
    "        print('Regularization By Lasso ')\n",
    "        print('-----------------------------')\n",
    "        for alpha in [0.00001,0.0001,0.001,0.01,0.1,0,1,10,100,1000] :\n",
    "            poly = PolynomialFeatures(degree = 15)\n",
    "            x_poly = poly.fit_transform(self.x.values.reshape(-1,1))\n",
    "            scl = StandardScaler()\n",
    "            x_scl = scl.fit_transform(x_poly)\n",
    "            lr_poly = Lasso(alpha=alpha)\n",
    "            lr_poly.fit(x_scl,self.y)\n",
    "            preds_poly = lr_poly.predict(x_scl)\n",
    "            print('alpha = ',alpha)\n",
    "            print('R^2 Score after poly ---> ' , r2_score(self.y , preds_poly))\n",
    "            plt.scatter(self.x,self.y)\n",
    "            plt.plot(self.x,preds_poly,color='r')\n",
    "            plt.show()\n",
    "        print('-----------------------------')\n",
    "        print('Regularization By Ridge ')\n",
    "        print('-----------------------------')\n",
    "        for alpha in [0.00001,0.0001,0.001,0.01,0.1,0,1,10,100,1000] :\n",
    "            poly = PolynomialFeatures(degree=15)\n",
    "            x_poly = poly.fit_transform(self.x.values.reshape(-1,1))\n",
    "            scl = StandardScaler()\n",
    "            x_scl = scl.fit_transform(x_poly)\n",
    "            lr_poly =Ridge(alpha=alpha)\n",
    "            lr_poly.fit(x_scl,self.y)\n",
    "            preds_poly = lr_poly.predict(x_scl)\n",
    "            print('alpha = ',alpha)\n",
    "            print('R^2 Score after poly ---> ' , r2_score(self.y , preds_poly))\n",
    "            plt.scatter(self.x,self.y)\n",
    "            plt.plot(self.x,preds_poly,color='r')\n",
    "            plt.show()\n",
    "    def gradient_descent(self) :\n",
    "        sgdr = SGDRegressor()\n",
    "        poly = PolynomialFeatures(degree=15)\n",
    "        x_poly = poly.fit_transform(self.x.values.reshape(-1,1))\n",
    "        scl = StandardScaler()\n",
    "        x_scl = scl.fit_transform(x_poly)\n",
    "        x_scaled_1 = scl.fit_transform(self.x.values.reshape(-1,1)) \n",
    "        sgdr.fit(x_scaled_1,self.y)\n",
    "        preds_sgdr = sgdr.predict(x_scaled_1)\n",
    "        plt.scatter(self.x,self.y)\n",
    "        plt.plot(self.x, preds_sgdr,color = 'r')\n",
    "        plt.show()\n",
    "        mse = mean_squared_error(self.y, preds_sgdr)\n",
    "        r2 = r2_score(self.y, preds_sgdr)\n",
    "        mae = mean_absolute_error(self.y, preds_sgdr)\n",
    "        print(\"Mean Squared Error = \", mse)\n",
    "        print(\"R^2 Score = \", r2)\n",
    "        print(\"Mean Absolute Error = \", mae)\n",
    "        poly = PolynomialFeatures(degree=15)\n",
    "        x_poly = poly.fit_transform(self.x.values.reshape(-1,1))\n",
    "        scl = StandardScaler()\n",
    "        x_scl = scl.fit_transform(x_poly)\n",
    "        lr_poly = SGDRegressor()\n",
    "        lr_poly.fit(x_scl,self.y)\n",
    "        preds_poly = lr_poly.predict(x_scl)\n",
    "        plt.scatter(self.x,self.y)\n",
    "        plt.plot(self.x,preds_poly,color='r')\n",
    "        plt.show()\n",
    "        mse = mean_squared_error(self.y, preds_poly)\n",
    "        r2 = r2_score(self.y, preds_poly)\n",
    "        mae = mean_absolute_error(self.y, preds_poly)\n",
    "        print(\"Mean Squared Error = \", mse)\n",
    "        print(\"R^2 Score = \", r2)\n",
    "        print(\"Mean Absolute Error = \", mae)\n",
    "    def multilinear_regression(self) :\n",
    "        msc = MinMaxScaler()\n",
    "        x_scl = msc.fit_transform(self.x.values.reshape(-1,1))\n",
    "        print(' x after scaling = ' ,x_scl[0:5])\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x_scl,self.y)\n",
    "        preds = lr.predict(x_scl)\n",
    "        print('R^2 Score = ' , r2_score(self.y,preds))\n",
    "        plt.scatter(self.x,self.y)\n",
    "        plt.plot(self.x,preds,color='g')\n",
    "        plt.show()\n",
    "        poly = PolynomialFeatures(degree=4)\n",
    "        x_poly = poly.fit_transform(x_scl)\n",
    "        x_scaled_poly = msc.fit_transform(x_poly)\n",
    "        lr.fit(x_scaled_poly,self.y)\n",
    "        preds_poly = lr.predict(x_scaled_poly)\n",
    "        print('R^2 Score = ' , r2_score(self.y,preds))\n",
    "        plt.scatter(self.x,self.y)\n",
    "        plt.plot(self.x,preds_poly,color='r')\n",
    "        plt.show()\n",
    "    def model_evaluation(self) :\n",
    "        msc = MinMaxScaler()\n",
    "        x_scl = msc.fit_transform(self.x.values.reshape(-1,1))\n",
    "        print(' x after scaling = ' ,x_scl[0:10])\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x_scl,self.y)\n",
    "        preds = lr.predict(x_scl)\n",
    "        print('r2 score = ' , r2_score(self.y,preds))\n",
    "        poly = PolynomialFeatures(degree=4)\n",
    "        x_poly = poly.fit_transform(x_scl)\n",
    "        x_scaled_poly = msc.fit_transform(x_poly)\n",
    "        x_train , x_test , y_train , y_test = train_test_split(x_scaled_poly,self.y,test_size=0.2)\n",
    "        lr.fit(x_train,y_train)\n",
    "        train_preds = lr.predict(x_train)\n",
    "        test_preds = lr.predict(x_test)\n",
    "        print('before poly : ')\n",
    "        print('R^2 Score = ' , r2_score(y_train,train_preds))\n",
    "        print('R^2 Score = ' , r2_score(y_test,test_preds))\n",
    "        lr.fit(x_train,y_train)\n",
    "        train_preds = lr.predict(x_train)\n",
    "        test_preds = lr.predict(x_test)        \n",
    "        print('after poly : ')\n",
    "        print('R^2 Score = ' , r2_score(y_train,train_preds))\n",
    "        print('R^2 Score = ' , r2_score(y_test,test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a0b155",
   "metadata": {},
   "source": [
    "# Classification Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification:\n",
    "    def __init__(self, df, target):\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "        self.x = self.df.drop(self.target, axis=1)\n",
    "        self.x = StandardScaler().fit_transform(self.x)\n",
    "        self.y = self.df[self.target]\n",
    "    def logistic_regression(self) :\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        plot_confusion_matrix(clf,x_train,y_train)\n",
    "        plt.title('Confusion matrix for train')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for train',accuracy_score(y_train,train_pred))\n",
    "        print('Precision Score for train',precision_score(y_train,train_pred))\n",
    "        print('Recall Score for train',recall_score(y_test,test_pred))\n",
    "        print('Confusion matrix for test')\n",
    "        plot_confusion_matrix(clf,x_test,y_test)\n",
    "        plt.title('Confusion matrix for test')\n",
    "        plt.show()\n",
    "        print('Accuracy Score for test',accuracy_score(y_test,test_pred))\n",
    "        print('Precision Score for test',precision_score(y_test,test_pred))\n",
    "        print('Recall Score for train',recall_score(y_train,train_pred))\n",
    "        # visualization\n",
    "        x_loc = int(input('please enter location of x column : '))\n",
    "        y_loc = int(input('please enter location of y column : '))\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for itr in [1,2,5,10,50,100,1000]: \n",
    "            clf = LogisticRegression(max_iter=itr,solver='sag')\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', itr)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            pl.subplot(7,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,y_loc],c=y_train)\n",
    "            pl.title(f'iteration {itr} train')\n",
    "            i+=1\n",
    "            pl.subplot(7,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {itr} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "    def support_vector_machine(self) :\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        svc = SVC()\n",
    "        svc.fit(x_train,y_train)\n",
    "        train_preds = svc.predict(x_train)\n",
    "        test_preds = svc.predict(x_test)\n",
    "        print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "        print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "        for i in ['linear' , 'poly' , 'rbf'] :\n",
    "            svc = SVC(kernel=i)\n",
    "            svc.fit(x_train,y_train)\n",
    "            train_preds = svc.predict(x_train)\n",
    "            test_preds = svc.predict(x_test)\n",
    "            print('kernal = ', i)\n",
    "            print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "            print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "            print('--------------------------------------------------------')\n",
    "        for j in range(1,20) :\n",
    "            svc = SVC(kernel='poly',degree=j)\n",
    "            svc.fit(x_train,y_train)\n",
    "            train_preds = svc.predict(x_train)\n",
    "            test_preds = svc.predict(x_test)\n",
    "            print('kernal = ', j)\n",
    "            print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "            print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "            print('--------------------------------------------------------')\n",
    "        x_loc = int(input('please enter location of x column : '))\n",
    "        y_loc = int(input('please enter location of y column : '))\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for j in range(1,16) :\n",
    "            clf = SVC(kernel='poly',degree=j)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', j)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            pl.subplot(15,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,y_loc],c=y_train)\n",
    "            pl.title(f'iteration {j} train')\n",
    "            i+=1\n",
    "            pl.subplot(15,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {j} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        print('-------------------------------------------------------')\n",
    "        print('-------------------------------------------------------')\n",
    "        for j in ['linear','poly','rbf'] :\n",
    "            clf = SVC(kernel=j)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', j)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            pl.subplot(3,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,1],x_train[:,2],c=y_train)\n",
    "            pl.title(f'iteration {j} train')\n",
    "            i+=1\n",
    "            pl.subplot(3,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {j} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "    def K_nearest_neighbor(self) :\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        clf = KNeighborsClassifier()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_preds = clf.predict(x_train)\n",
    "        test_preds = clf.predict(x_test)\n",
    "        print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "        print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "        for i in range(1,10,2) :\n",
    "            clf = KNeighborsClassifier(n_neighbors=i)\n",
    "            clf.fit(x_train,y_train)\n",
    "            train_preds = clf.predict(x_train)\n",
    "            test_preds = clf.predict(x_test)\n",
    "            print('i = ' , i)\n",
    "            print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "            print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "            print('--------------------------------------------------------')\n",
    "        x_loc = int(input('please enter location of x column : '))\n",
    "        y_loc = int(input('please enter location of y column : '))\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for i in range(1,10,2) :\n",
    "            clf = KNeighborsClassifier(n_neighbors=i)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', i)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            pl.subplot(5,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,y_loc],c=y_train)\n",
    "            pl.title(f'iteration {i} train')\n",
    "            i+=1\n",
    "            pl.subplot(5,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,x_loc],c=y_test)\n",
    "            pl.title(f'iteration {i} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "        print('-------------------------------------------------------')\n",
    "        print('-------------------------------------------------------')\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for i in range(1,10,2) :\n",
    "            clf = KNeighborsClassifier(n_neighbors=i,p=1)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', i)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            pl.subplot(5,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,y_loc],c=y_train)\n",
    "            pl.title(f'iteration {i} train')\n",
    "            i+=1\n",
    "            pl.subplot(5,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {i} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "    def decision_tree(self) :\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        clf = DecisionTreeClassifier()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_preds = clf.predict(x_train)\n",
    "        test_preds = clf.predict(x_test)\n",
    "        print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "        print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "        print('-------------------------------------------------------')\n",
    "        print('-------------------------------------------------------')\n",
    "        x_loc = int(input('please enter location of x column : '))\n",
    "        y_loc = int(input('please enter location of y column : '))\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for j in range(1,10) :\n",
    "            clf = DecisionTreeClassifier(max_depth=j)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', j)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            pl.subplot(9,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,y_loc],c=y_train)\n",
    "            pl.title(f'iteration {j} train')\n",
    "            i+=1\n",
    "            pl.subplot(9,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {j} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "    def random_forest(self) :\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_preds = clf.predict(x_train)\n",
    "        test_preds = clf.predict(x_test)\n",
    "        print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "        print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "        print('------------------------------------')\n",
    "        for i in [1,2,5,10,20,50,100,1000] :\n",
    "            clf = RandomForestClassifier(n_estimators = i)\n",
    "            clf.fit(x_train,y_train)\n",
    "            train_preds = clf.predict(x_train)\n",
    "            test_preds = clf.predict(x_test)\n",
    "            print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "            print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "            print('------------------------------------')\n",
    "        x_loc = int(input('please enter location of x column : '))\n",
    "        y_loc = int(input('please enter location of y column : '))\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for j in [1,2,5,10,20,50,100,1000] :\n",
    "            clf = RandomForestClassifier(n_estimators = j)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', j)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            print('------------------------------------')\n",
    "            pl.subplot(8,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,y_loc],c=y_train)\n",
    "            pl.title(f'iteration {j} train')\n",
    "            i+=1\n",
    "            pl.subplot(8,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {j} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for j in range(1,10) :\n",
    "            clf = RandomForestClassifier(max_depth= j)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', j)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            print('------------------------------------')\n",
    "            pl.subplot(9,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,x_loc],c=y_train)\n",
    "            pl.title(f'iteration {j} train')\n",
    "            i+=1\n",
    "            pl.subplot(9,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {j} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "    def boosting(self) :\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        clf = XGBClassifier()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_preds = clf.predict(x_train)\n",
    "        test_preds = clf.predict(x_test)\n",
    "        print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "        print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "        print('--------------------------------------------------------')\n",
    "        clf = XGBClassifier()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_preds = clf.predict(x_train)\n",
    "        test_preds = clf.predict(x_test)\n",
    "        print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "        print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "        print('--------------------------------------------------------')\n",
    "        x_loc = int(input('please enter location of x column : '))\n",
    "        y_loc = int(input('please enter location of y column : '))\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for j in [0,1,5,10,50,100] :\n",
    "            clf = XGBClassifier(gamma=j)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', j)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            print('------------------------------------')\n",
    "            pl.subplot(8,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,y_loc],c=y_train)\n",
    "            pl.title(f'iteration {j} train')\n",
    "            i+=1\n",
    "            pl.subplot(8,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {j} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for j in [0,1,5,10,50,100]:\n",
    "            clf = RandomForestClassifier(eta= j)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', j)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            print('------------------------------------')\n",
    "            pl.subplot(9,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,x_loc],c=y_train)\n",
    "            pl.title(f'iteration {j} train')\n",
    "            i+=1\n",
    "            pl.subplot(9,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {j} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "        x_min,x_max = self.x[:,x_loc].min()-1 , self.x[:,x_loc].max()+1\n",
    "        y_min,y_max = self.x[:,y_loc].min()-1 , self.x[:,y_loc].max()+1\n",
    "        x_grid , y_grid = np.meshgrid(np.arange(x_min,x_max,0.02),np.arange(y_min,y_max,0.02))\n",
    "        pl.figure(figsize=(15,30))\n",
    "        pl.set_cmap(pl.cm.cividis)\n",
    "        i = 1\n",
    "        for j in [0,1,5,10,50,100]:\n",
    "            clf = RandomForestClassifier(max_depth= j)\n",
    "            clf.fit(x_train[:,x_loc:],y_train)\n",
    "            train_pred = clf.predict(x_train[:,x_loc:])\n",
    "            test_pred = clf.predict(x_test[:,x_loc:])\n",
    "            print('iterations = ', j)\n",
    "            print('tarin accuracy = ',accuracy_score(y_train,train_pred))\n",
    "            print('test accuracy = ',accuracy_score(y_test,test_pred))\n",
    "            print('------------------------------------')\n",
    "            pl.subplot(9,2,i)\n",
    "            z = clf.predict(np.c_[x_grid.ravel(),y_grid.ravel()])\n",
    "            z = z.reshape(x_grid.shape)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_train[:,x_loc],x_train[:,x_loc],c=y_train)\n",
    "            pl.title(f'iteration {j} train')\n",
    "            i+=1\n",
    "            pl.subplot(9,2,i)\n",
    "            pl.set_cmap(pl.cm.cividis)\n",
    "            pl.contourf(x_grid,y_grid,z)\n",
    "            pl.axis('tight')\n",
    "            pl.scatter(x_test[:,x_loc],x_test[:,y_loc],c=y_test)\n",
    "            pl.title(f'iteration {j} test')\n",
    "            i+=1\n",
    "        pl.axis('tight')\n",
    "        pl.show()\n",
    "    def cross_validation(self) :\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_preds = clf.predict(x_train)\n",
    "        test_preds = clf.predict(x_test)\n",
    "        print('train accuracy = ', accuracy_score(y_train,train_preds))\n",
    "        print('test accuracy = ', accuracy_score(y_test,test_preds))\n",
    "        clf = RandomForestClassifier()\n",
    "        kf = StratifiedKFold(n_splits = 5)\n",
    "        acc_list = []\n",
    "        for train_idx , test_idx in kf.split(self.x,self.y) :\n",
    "            train_data = self.x[train_idx]\n",
    "            test_data = self.x[test_idx]\n",
    "            train_y = self.y.iloc[train_idx]\n",
    "            test_y = self.y.iloc[test_idx]\n",
    "            clf.fit(train_data,train_y)\n",
    "            preds = clf.predict(test_data)\n",
    "            acc = accuracy_score(test_y, preds)\n",
    "            acc_list.append(acc)\n",
    "        print('List of accuracies = ', acc_list)\n",
    "    def hyper_parameter_tuning(self) :\n",
    "        x_train , x_test , y_train , y_test = train_test_split(self.x,self.y,test_size = 0.2 , shuffle = True)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(x_train,y_train)\n",
    "        train_pred = clf.predict(x_train)\n",
    "        test_pred = clf.predict(x_test)\n",
    "        parameters = {'n_estimators' : [10,20,50,70,100],'max_depth' : [1,2,3,4,5]}\n",
    "        clf = RandomForestClassifier()\n",
    "        gsclf = GridSearchCV(clf,parameters)\n",
    "        gsclf.fit(x_train,y_train)\n",
    "        dgs = pd.DataFrame(gsclf.cv_results_)\n",
    "        print(dgs[0:5])\n",
    "        model = gsclf.best_estimator_\n",
    "        #print(model)\n",
    "        model.fit(x_train,y_train)\n",
    "        preds = model.predict(x_test)\n",
    "        print('------------------------------------------------')\n",
    "        print('Accuracy Score = ',accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b44d3",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # calling for methods\n",
    "    file_type = ['.csv','.xlsx','.sql']\n",
    "    file_path = get_files(file_type)\n",
    "    df = check_file_path(file_path)\n",
    "    print('------------------------------------')\n",
    "    drop_columns(df)\n",
    "    print('------------------------------------')\n",
    "    df = data_preprocessing(df)\n",
    "    print('------------------------------------')\n",
    "    x,y = choose_features(df)\n",
    "    print('------------------------------------')\n",
    "    target = choose_target_column(df)\n",
    "    print('------------------------------------')\n",
    "    choose_model_and_algorithm(x,y,df,target)    \n",
    "    # take object from classes to use there functionality\n",
    "    \n",
    "    regression = Regression(x,y)\n",
    "    \n",
    "    print('all regression methods')\n",
    "    print('------------------------------------')\n",
    "    regression.simple_regression()\n",
    "    print('------------------------------------')\n",
    "    regression.polynomial_features()\n",
    "    print('------------------------------------')\n",
    "    regression.Regularization()\n",
    "    print('------------------------------------')\n",
    "    regression.gradient_descent()\n",
    "    print('------------------------------------')\n",
    "    regression.multilinear_regression()\n",
    "    print('------------------------------------')\n",
    "    regression.model_evaluation()\n",
    "    print('------------------------------------')\n",
    "    \n",
    "    classification = Classification(df,target)\n",
    "    \n",
    "    print('all classification methods')\n",
    "    print('------------------------------------')\n",
    "    classification.logistic_regression()\n",
    "    print('------------------------------------')\n",
    "    classification.support_vector_machine()\n",
    "    print('------------------------------------')\n",
    "    classification.K_nearest_neighbor()\n",
    "    print('------------------------------------')\n",
    "    classification.decision_tree()\n",
    "    print('------------------------------------')\n",
    "    classification.random_forest()\n",
    "    print('------------------------------------')\n",
    "    classification.boosting()\n",
    "    print('------------------------------------')\n",
    "    classification.cross_validation()\n",
    "    print('------------------------------------')\n",
    "    classification.hyper_parameter_tuning()\n",
    "    print('------------------------------------')\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92729d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
